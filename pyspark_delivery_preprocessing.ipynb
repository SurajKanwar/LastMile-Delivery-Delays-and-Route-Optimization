{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9726e21e-677c-46e9-b21c-64112e0d0253",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c0941bb-8226-4f18-bdb3-8caf1fe0b538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.feature import Imputer\n",
    "spark = SparkSession.builder.appName('PysparkTransformation').getOrCreate()\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7206658b-4517-4cea-997b-cc6572b7115c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Read the pickup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b386fbdf-b97f-4514-9bec-9597cc4e7e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery_file = r'C:\\Users\\Dusty\\Downloads\\Internship\\Last-Mile-Delivery-Delays-and-Route-Optimization\\data\\delivery_data.csv'\n",
    "df_delivery = spark.read.csv(delivery_file,header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e29ddc84-78fa-4646-9dc2-39fb95794117",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+---------+----------+---------+--------+------+--------+--------------+---------------+--------------+--------------+--------------+-----------------+----------------+----------------+----+\n",
      "|order_id|region_id|     city|courier_id|      lng|     lat|aoi_id|aoi_type|   accept_time|accept_gps_time|accept_gps_lng|accept_gps_lat| delivery_time|delivery_gps_time|delivery_gps_lng|delivery_gps_lat|  ds|\n",
      "+--------+---------+---------+----------+---------+--------+------+--------+--------------+---------------+--------------+--------------+--------------+-----------------+----------------+----------------+----+\n",
      "| 1034452|      158|Chongqing|      1014|106.52605| 29.6391| 20067|       1|07-26 13:38:00| 07-26 13:38:00|     106.52121|      29.62357|07-26 20:47:00|   07-26 20:47:00|       106.47765|        29.62664| 726|\n",
      "| 1001537|       27| Hangzhou|      2947|120.11555|30.29957| 21312|       1|07-16 17:06:00| 07-16 17:06:00|     120.12521|      30.29694|07-16 19:42:00|   07-16 19:42:00|       120.11465|        30.29893| 716|\n",
      "| 1565655|       84| Shanghai|      2001|121.53117|31.21679| 24732|       2|09-24 17:55:00| 09-24 17:55:00|     121.53041|      31.21678|09-24 19:17:00|   09-24 19:17:00|       121.53115|        31.21677| 924|\n",
      "|  370216|       40|Chongqing|       764|106.51614|29.53909| 57008|       7|10-25 08:22:00| 10-25 08:22:00|     106.50124|      29.53616|10-25 16:25:00|   10-25 16:25:00|       106.51668|        29.53961|1025|\n",
      "+--------+---------+---------+----------+---------+--------+------+--------+--------------+---------------+--------------+--------------+--------------+-----------------+----------------+----------------+----+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import : from pyspark.sql.functions import rand\n",
    "df_delivery.orderBy(rand()).show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0eeb125d-3a1b-4e66-b694-9db4313cd203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records: 4514661\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of records: {df_delivery.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da25052e-86a4-4185-b57e-4960b82c3203",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Convert String Timestamps to timestamp Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64425fd3-8b8e-401f-886a-3c32f20023f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- region_id: integer (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- courier_id: integer (nullable = true)\n",
      " |-- lng: double (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- aoi_id: integer (nullable = true)\n",
      " |-- aoi_type: integer (nullable = true)\n",
      " |-- accept_time: string (nullable = true)\n",
      " |-- accept_gps_time: string (nullable = true)\n",
      " |-- accept_gps_lng: double (nullable = true)\n",
      " |-- accept_gps_lat: double (nullable = true)\n",
      " |-- delivery_time: string (nullable = true)\n",
      " |-- delivery_gps_time: string (nullable = true)\n",
      " |-- delivery_gps_lng: double (nullable = true)\n",
      " |-- delivery_gps_lat: double (nullable = true)\n",
      " |-- ds: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_delivery.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c64df8b7-55b1-427a-972b-45ffdbbac278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current year dynamically as with adding its taking 1970 as default year as there is no year in csv file and excel is showing byfault the current year\n",
    "current_year = date_format(col(\"current_date\"), \"yyyy\")\n",
    "\n",
    "# Convert all date columns by prepending the current year\n",
    "df_delivery = df_delivery.withColumn(\"accept_time\", to_timestamp(concat(current_year, lit(\"-\"), trim(col(\"accept_time\"))), \"yyyy-MM-dd HH:mm:ss\")) \\\n",
    "       .withColumn(\"delivery_time\", to_timestamp(concat(current_year, lit(\"-\"), trim(col(\"delivery_time\"))), \"yyyy-MM-dd HH:mm:ss\")) \\\n",
    "       .withColumn(\"delivery_gps_time\", to_timestamp(concat(current_year, lit(\"-\"), trim(col(\"delivery_gps_time\"))), \"yyyy-MM-dd HH:mm:ss\")) \\\n",
    "       .withColumn(\"accept_gps_time\", to_timestamp(concat(current_year, lit(\"-\"), trim(col(\"accept_gps_time\"))), \"yyyy-MM-dd HH:mm:ss\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c18de7f1-8eaf-4814-8f84-bdf32801b28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- region_id: integer (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- courier_id: integer (nullable = true)\n",
      " |-- lng: double (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- aoi_id: integer (nullable = true)\n",
      " |-- aoi_type: integer (nullable = true)\n",
      " |-- accept_time: timestamp (nullable = true)\n",
      " |-- accept_gps_time: timestamp (nullable = true)\n",
      " |-- accept_gps_lng: double (nullable = true)\n",
      " |-- accept_gps_lat: double (nullable = true)\n",
      " |-- delivery_time: timestamp (nullable = true)\n",
      " |-- delivery_gps_time: timestamp (nullable = true)\n",
      " |-- delivery_gps_lng: double (nullable = true)\n",
      " |-- delivery_gps_lat: double (nullable = true)\n",
      " |-- ds: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_delivery.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6d7746c-0110-4647-ad09-d2f52cf3b330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|      delivery_time|\n",
      "+-------------------+\n",
      "|2025-10-30 10:30:00|\n",
      "|2025-10-31 10:40:00|\n",
      "|2025-10-22 15:03:00|\n",
      "|2025-10-26 10:30:00|\n",
      "|2025-10-31 16:41:00|\n",
      "+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_delivery.select(\"delivery_time\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048d31d4-94f4-44a7-ada2-eb0dbfbd4da0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Dropping Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "991d135e-2e24-431c-9f6a-16508e847109",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delivery = df_delivery.dropDuplicates([\"order_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696c8acc-5e89-4e01-b8ea-2d47f4ef343c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Handle missing values using dropna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dfa0730-1317-4d5f-b55c-f206b80658dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping order_id and courier_idif they are missing as they are important\n",
    "df_delivery = df_delivery.dropna(subset=[\"order_id\", \"courier_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c7528f5-5ac5-4aee-a9c6-b9c5f1bf84fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records: 4514661\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of records: {df_delivery.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece4e899-9a03-4538-bd0b-679dd962d611",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Handle Missing values using imputation strategies where necessary. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7802c425-f3cf-4097-a8d2-3e33e65f8a25",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Mean Imputation for Numeric Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f817e2c-7889-458f-b38f-7da58ae484f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [\"lng\", \"lat\", \"delivery_gps_lng\", \"delivery_gps_lat\", \"accept_gps_lng\", \"accept_gps_lat\"]\n",
    "\n",
    "# Create Imputer to fill missing numeric values with mean\n",
    "imputer = Imputer(inputCols=numeric_cols, outputCols=[c + \"_imputed\" for c in numeric_cols], strategy=\"mean\")\n",
    "\n",
    "# Apply Imputer\n",
    "df_delivery = imputer.fit(df_delivery).transform(df_delivery)\n",
    "# Round the imputed values to 5 decimal places\n",
    "for col_name in numeric_cols:\n",
    "    df_delivery = df_delivery.withColumn(col_name + \"_imputed\", round(col(col_name + \"_imputed\"), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e161dace-1dc1-49b2-9541-28ab35b31d4e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### To Check the imputed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3ebb9ec-c558-43c6-a46d-a294d6f8871e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+----------------+----------------+--------------+--------------+-----------+-----------+------------------------+------------------------+----------------------+----------------------+\n",
      "|      lng|     lat|delivery_gps_lng|delivery_gps_lat|accept_gps_lng|accept_gps_lat|lng_imputed|lat_imputed|delivery_gps_lng_imputed|delivery_gps_lat_imputed|accept_gps_lng_imputed|accept_gps_lat_imputed|\n",
      "+---------+--------+----------------+----------------+--------------+--------------+-----------+-----------+------------------------+------------------------+----------------------+----------------------+\n",
      "|120.17887|30.26379|       120.17803|         30.2638|     120.20605|      30.28655|  120.17887|   30.26379|               120.17803|                 30.2638|             120.20605|              30.28655|\n",
      "|120.17887|30.26417|       120.18027|          30.263|     120.18549|      30.28065|  120.17887|   30.26417|               120.18027|                  30.263|             120.18549|              30.28065|\n",
      "|120.18379|30.25993|       120.18393|        30.25991|     120.18544|      30.28074|  120.18379|   30.25993|               120.18393|                30.25991|             120.18544|              30.28074|\n",
      "|120.18467|30.26117|       120.18461|        30.26102|     120.20603|      30.28662|  120.18467|   30.26117|               120.18461|                30.26102|             120.20603|              30.28662|\n",
      "|120.18509| 30.2613|       120.18468|        30.26087|     120.18541|      30.28078|  120.18509|    30.2613|               120.18468|                30.26087|             120.18541|              30.28078|\n",
      "+---------+--------+----------------+----------------+--------------+--------------+-----------+-----------+------------------------+------------------------+----------------------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define numeric columns that were imputed\n",
    "numeric_cols = [\"lng\", \"lat\",\"delivery_gps_lng\", \"delivery_gps_lat\", \"accept_gps_lng\", \"accept_gps_lat\"]\n",
    "# Select original and imputed columns for comparison\n",
    "df_delivery.select([col(c) for c in numeric_cols] + [col(c + \"_imputed\") for c in numeric_cols]).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311e3c50-866a-475f-b2c0-3b0a4d94ecd4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Drop original columns and rename imputed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74ecb495-90ec-4abf-8fd1-ff4ca0985da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in numeric_cols:\n",
    "    df_delivery = df_delivery.drop(col_name).withColumnRenamed(col_name + \"_imputed\", col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fe6a1fc-a090-4eed-95f7-1141b87c7b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+---------+----------+------+--------+-------------------+-------------------+-------------------+-------------------+----+---------+--------+----------------+----------------+--------------+--------------+\n",
      "|order_id|region_id|     city|courier_id|aoi_id|aoi_type|        accept_time|    accept_gps_time|      delivery_time|  delivery_gps_time|  ds|      lng|     lat|delivery_gps_lng|delivery_gps_lat|accept_gps_lng|accept_gps_lat|\n",
      "+--------+---------+---------+----------+------+--------+-------------------+-------------------+-------------------+-------------------+----+---------+--------+----------------+----------------+--------------+--------------+\n",
      "|      31|       98| Hangzhou|       300| 42283|      14|2025-07-23 07:54:00|2025-07-23 07:54:00|2025-07-23 09:26:00|2025-07-23 09:26:00| 723|120.44703|30.31246|       120.44639|        30.31075|     120.53647|      30.27606|\n",
      "|      53|       90| Shanghai|      2144| 32101|       1|2025-09-13 13:43:00|2025-09-13 13:43:00|2025-09-13 14:50:00|2025-09-13 14:50:00| 913|121.43628|31.16883|       121.43621|        31.16883|     121.45472|      31.16736|\n",
      "|      65|       47| Hangzhou|       363| 52701|       1|2025-08-24 10:36:00|2025-08-24 10:36:00|2025-08-24 13:57:00|2025-08-24 13:57:00| 824|119.06412|29.61213|       119.06396|        29.61493|     119.10327|      29.61125|\n",
      "|      78|      109|Chongqing|      2415| 39454|       4|2025-10-31 08:25:00|2025-10-31 08:25:00|2025-10-31 15:00:00|2025-10-31 15:00:00|1031|106.44671|29.60255|       106.44718|        29.60343|     106.44463|      29.60026|\n",
      "|      85|      124| Hangzhou|       823|  5097|       7|2025-10-29 10:13:00|2025-10-29 10:13:00|2025-10-29 12:03:00|2025-10-29 12:03:00|1029|120.19409|30.24744|       120.19423|        30.24756|     120.20243|      30.26579|\n",
      "+--------+---------+---------+----------+------+--------+-------------------+-------------------+-------------------+-------------------+----+---------+--------+----------------+----------------+--------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_delivery.select(\"*\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af94007-93f1-4c1e-b442-e41b6f7397c6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Mode Imputation for Categorical Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1bcedf7-0a53-452c-ab34-003993eff88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For categorical fields (city, region_id, aoi_type), we replace missing values with the most frequent value (mode).\n",
    "categorical_cols = [\"city\", \"region_id\", \"aoi_type\"]\n",
    "\n",
    "for cat_cols in categorical_cols:\n",
    "    mode_value = df_delivery.groupBy(cat_cols).count().orderBy(col(\"count\").desc()).first()[0] # Get most frequent value\n",
    "    df_delivery.fillna({cat_cols: mode_value}) # Fill missing values with mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6957d6ff-afe3-48cf-9f8a-1b113811253b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------+\n",
      "|     city|region_id|aoi_type|\n",
      "+---------+---------+--------+\n",
      "| Hangzhou|       98|      14|\n",
      "| Shanghai|       90|       1|\n",
      "| Hangzhou|       47|       1|\n",
      "|Chongqing|      109|       4|\n",
      "| Hangzhou|      124|       7|\n",
      "+---------+---------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_delivery.select(\"city\", \"region_id\", \"aoi_type\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daa7a39-a804-48f2-9595-e84aa8a2c6ff",
   "metadata": {},
   "source": [
    "#### Forward Fill (Last Known Value) for Timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f6cb2c-f8aa-4492-9b19-0172315b6123",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Removing unnecessary columns i.e. delivery_gps_time and accept_gps_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f1be4e2-b3f5-4d37-9c9d-b4b3fb9b8eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before filling the timestamp notice in the csv file that delivery_time and delivery_gps_time have same values same for accept_time & accept_gps_time.\n",
    "# therefore we can drop these columns delivery_gps_time and accept_gps_time.\n",
    "# Assuming you have a DataFrame named df\n",
    "df_delivery = df_delivery.drop('delivery_gps_time', 'accept_gps_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ef66c91-141c-4e8a-932e-c798ee01800b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- region_id: integer (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- courier_id: integer (nullable = true)\n",
      " |-- aoi_id: integer (nullable = true)\n",
      " |-- aoi_type: integer (nullable = true)\n",
      " |-- accept_time: timestamp (nullable = true)\n",
      " |-- delivery_time: timestamp (nullable = true)\n",
      " |-- ds: integer (nullable = true)\n",
      " |-- lng: double (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- delivery_gps_lng: double (nullable = true)\n",
      " |-- delivery_gps_lat: double (nullable = true)\n",
      " |-- accept_gps_lng: double (nullable = true)\n",
      " |-- accept_gps_lat: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_delivery.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9eb631-fe74-4ef1-ab15-f9c7d1f2da18",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Forward/Backward Filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6090df7a-12fd-42ac-9dfd-138ad34416f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first row in a partition (grouped by courier_id) remains NULL because there is no previous value to carry forward. \n",
    "# The forward fill approach only propagates past values forward, but it doesn't backfill the first row if it was originally NULL in the very starting rows.\n",
    "# To fix this, we need to first fill missing values with the earliest available timestamp in the partition (backfill), then apply forward filling\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Define a global forward-fill and backward-fill window\n",
    "window_forward = Window.orderBy(\"accept_time\").rowsBetween(-sys.maxsize, 0)  # Forward fill\n",
    "window_backward = Window.orderBy(F.col(\"accept_time\").desc()).rowsBetween(-sys.maxsize, 0)  # Backward fill\n",
    "\n",
    "time_cols = [\"accept_time\", \"delivery_time\"]\n",
    "\n",
    "for time_col in time_cols:\n",
    "    df_delivery = df_delivery.withColumn(time_col, \n",
    "        F.coalesce(\n",
    "            F.last(time_col, ignorenulls=True).over(window_forward),  # Forward fill\n",
    "            F.first(time_col, ignorenulls=True).over(window_backward)  # Backward fill\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cf03c38-1dc8-4e8b-b4dd-1495bd66b6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n",
      "|      delivery_time|        accept_time|\n",
      "+-------------------+-------------------+\n",
      "|2025-10-30 10:30:00|2025-10-30 09:20:00|\n",
      "+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_delivery.filter(df_delivery.order_id == \"583722\").select(\"delivery_time\", \"accept_time\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dfa57ee8-346d-4481-b437-1b72d8f956d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+\n",
      "|accept_time|delivery_time|\n",
      "+-----------+-------------+\n",
      "|          0|            0|\n",
      "+-----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_delivery.select([count(when(col(c).isNull(), 1)).alias(c) for c in time_cols]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76933e5a-1822-4b77-b779-59ab383bd3a0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Convert categorical fields (e.g., aoi_type, city, region_id) to a consistent format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70982b0b-1201-42f8-9853-98e21da44f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delivery = df_delivery.withColumn(\"city\", trim(initcap(col(\"city\")))) \\\n",
    "       .withColumn(\"region_id\", col(\"region_id\").cast(\"int\")) \\\n",
    "       .withColumn(\"aoi_type\", col(\"aoi_type\").cast(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2991124-08aa-48fa-917d-9ccaab79e801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------+\n",
      "|     city|region_id|aoi_type|\n",
      "+---------+---------+--------+\n",
      "| Hangzhou|       98|      14|\n",
      "| Shanghai|       90|       1|\n",
      "| Hangzhou|       47|       1|\n",
      "|Chongqing|      109|       4|\n",
      "| Hangzhou|      124|       7|\n",
      "+---------+---------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_delivery.select(\"city\", \"region_id\", \"aoi_type\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07061111-6702-477f-bae9-1198a40676da",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Removing or fixing inconsistent geospatial coordinates (lng/lat)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c15775d-068f-402a-b26c-c21cfdbd21a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_cols = [\"lat\", \"delivery_gps_lat\", \"accept_gps_lat\"]\n",
    "lng_cols = [\"lng\", \"delivery_gps_lng\", \"accept_gps_lng\"]\n",
    "\n",
    "# Keep only valid latitudes (-90 to 90)\n",
    "for col_name in lat_cols:\n",
    "    df_delivery = df_delivery.withColumn(col_name, when((col(col_name) >= -90) & (col(col_name) <= 90), col(col_name)).otherwise(None))\n",
    "\n",
    "# Keep only valid longitudes (-180 to 180)\n",
    "for col_name in lng_cols:\n",
    "    df_delivery = df_delivery.withColumn(col_name, when((col(col_name) >= -180) & (col(col_name) <= 180), col(col_name)).otherwise(None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6b18ba0-a72c-468f-9ebe-8bb8ebe8c8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+----------------+----------------+--------------+--------------+\n",
      "|      lng|     lat|delivery_gps_lng|delivery_gps_lat|accept_gps_lng|accept_gps_lat|\n",
      "+---------+--------+----------------+----------------+--------------+--------------+\n",
      "|120.17887|30.26379|       120.17803|         30.2638|     120.20605|      30.28655|\n",
      "|120.17887|30.26417|       120.18027|          30.263|     120.18549|      30.28065|\n",
      "|120.18379|30.25993|       120.18393|        30.25991|     120.18544|      30.28074|\n",
      "|120.18467|30.26117|       120.18461|        30.26102|     120.20603|      30.28662|\n",
      "|120.18509| 30.2613|       120.18468|        30.26087|     120.18541|      30.28078|\n",
      "+---------+--------+----------------+----------------+--------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_delivery.select(\"lng\", \"lat\",\"delivery_gps_lng\", \"delivery_gps_lat\", \"accept_gps_lng\", \"accept_gps_lat\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a444fbc-7b57-4d0c-968a-0293f04593d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----------------+----------------+--------------+--------------+\n",
      "|lng|lat|delivery_gps_lng|delivery_gps_lat|accept_gps_lng|accept_gps_lat|\n",
      "+---+---+----------------+----------------+--------------+--------------+\n",
      "|  0|  0|               0|               0|             0|             0|\n",
      "+---+---+----------------+----------------+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#checking any of the column is still null \n",
    "time_cols = [\"lng\", \"lat\",\"delivery_gps_lng\", \"delivery_gps_lat\", \"accept_gps_lng\", \"accept_gps_lat\"]\n",
    "df_delivery.select([count(when(col(c).isNull(), 1)).alias(c) for c in time_cols]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914a3cfb-1d19-4099-be1f-a8f2d7973f50",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Identify any anomalies in timestamps (e.g., deliveries before pickups) & Checking for incorrect or negative time differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f14a2ed-41af-4606-9ce9-875d6349a172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for \"accepts before pickups\" (accept_time > delivery_time)\n",
    "df_delivery = df_delivery.withColumn(\n",
    "    \"accept_before_delivery\",\n",
    "    when(col(\"accept_time\") > col(\"delivery_time\"), True).otherwise(False)\n",
    ")\n",
    "\n",
    "# Check for negative or incorrect time differences between accept_time and delivery_time\n",
    "df_delivery = df_delivery.withColumn(\n",
    "    \"time_difference\",\n",
    "    (unix_timestamp(\"delivery_time\") - unix_timestamp(\"accept_time\"))\n",
    ")\n",
    "\n",
    "# Flag negative time differences\n",
    "df_delivery = df_delivery.withColumn(\n",
    "    \"negative_time_difference\",\n",
    "    when(col(\"time_difference\") < 0, True).otherwise(False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d785fd64-1b41-40ac-bcfd-afccb23c09eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+------------------------+\n",
      "|accept_before_delivery|negative_time_difference|\n",
      "+----------------------+------------------------+\n",
      "|                  true|                    true|\n",
      "|                  true|                    true|\n",
      "|                  true|                    true|\n",
      "+----------------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter for anomalies\n",
    "anomalies = df_delivery.filter((col(\"accept_before_delivery\") == True) | (col(\"negative_time_difference\") == True))\n",
    "\n",
    "# Show anomalies\n",
    "anomalies.select(\"accept_before_delivery\", \"negative_time_difference\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb70488a-cc03-47ad-b25a-2fb5d9c4c20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delivery = df_delivery.drop('accept_before_delivery','time_difference', 'negative_time_difference')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36634a1-dbf0-4c88-ac2f-b57b160bdf75",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Creating derived feature: Delivery ETA = delivery_time - accept_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75a38f75-c034-424a-8f1f-4e21936450f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Calculate Delivery Delay\n",
    "df_delivery = df_delivery.withColumn(\n",
    "    \"delivery_eta_minutes\", \n",
    "    ((F.unix_timestamp(\"delivery_time\") - F.unix_timestamp(\"accept_time\"))/60).cast(\"double\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d105d44-3878-48ed-b8dc-83b0e7b3244c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|delivery_eta_minutes|\n",
      "+--------------------+\n",
      "|             19188.0|\n",
      "|                 2.0|\n",
      "|                 0.0|\n",
      "|                 3.0|\n",
      "|                 1.0|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_delivery.select('delivery_eta_minutes').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7764c017-3bbc-47f4-bce1-331748d09d14",
   "metadata": {},
   "source": [
    "### Saving the cleaned data in a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4f49bc3-42c8-42b1-b582-f309fcb6492a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Delivery data saved successfully\n"
     ]
    }
   ],
   "source": [
    "time_cols = [\"accept_time\", \"delivery_time\"]\n",
    "\n",
    "# Format the timestamp columns to match the desired format as directly saving to csv file is giving wrong format for dates columns.\n",
    "for time_col in time_cols:\n",
    "    df_delivery = df_delivery.withColumn(\n",
    "        time_col, \n",
    "        date_format(time_col, \"yyyy-MM-dd HH:mm:ss\")\n",
    "    )\n",
    "\n",
    "output_path = r'C:\\Users\\Dusty\\Downloads\\Internship\\Last-Mile-Delivery-Delays-and-Route-Optimization\\data\\cleaned_delivery_data.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df_delivery.coalesce(1).write.csv(output_path, header=True, mode=\"overwrite\")\n",
    "print(f\"Cleaned Delivery data saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ded56625-60f9-438b-9c02-2da79c26a3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the DataFrame: 4514661\n"
     ]
    }
   ],
   "source": [
    "row_count1 = df_delivery.count()\n",
    "print(f\"Number of rows in the DataFrame: {row_count1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd3990d-6f42-488b-9588-7d145f782bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
