{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9726e21e-677c-46e9-b21c-64112e0d0253",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c0941bb-8226-4f18-bdb3-8caf1fe0b538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.feature import Imputer\n",
    "spark = SparkSession.builder.appName('PysparkTransformation').getOrCreate()\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7206658b-4517-4cea-997b-cc6572b7115c",
   "metadata": {},
   "source": [
    "### Read the pickup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b386fbdf-b97f-4514-9bec-9597cc4e7e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickup_file = r'C:\\Users\\Dusty\\Downloads\\Internship\\Last-Mile-Delivery-Delays-and-Route-Optimization\\data\\pickup_data.csv'\n",
    "df_pickup = spark.read.csv(pickup_file,header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e29ddc84-78fa-4646-9dc2-39fb95794117",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+--------+----------+--------------+-----------------+---------------+---------+--------+------+--------+--------------+---------------+--------------+--------------+---------------+--------------+--------------+----+\n",
      "|order_id|region_id|    city|courier_id|   accept_time|time_window_start|time_window_end|      lng|     lat|aoi_id|aoi_type|   pickup_time|pickup_gps_time|pickup_gps_lng|pickup_gps_lat|accept_gps_time|accept_gps_lng|accept_gps_lat|  ds|\n",
      "+--------+---------+--------+----------+--------------+-----------------+---------------+---------+--------+------+--------+--------------+---------------+--------------+--------------+---------------+--------------+--------------+----+\n",
      "|  835595|      134|  Yantai|      6190|06-15 08:08:00|   06-15 09:00:00| 06-15 11:00:00|121.34875| 37.5794|  1619|       1|06-15 08:27:00| 06-15 08:27:00|     121.35092|      37.57914| 06-15 08:08:00|     121.37013|      37.55683| 615|\n",
      "| 6042873|      116|  Yantai|      2332|10-12 13:42:00|   10-12 15:00:00| 10-12 17:00:00|121.16929|37.57506| 16714|      14|10-12 15:14:00| 10-12 15:14:00|     121.16876|      37.57414| 10-12 13:41:00|     121.15854|      37.58594|1012|\n",
      "|  381627|      107|  Yantai|      6142|06-25 08:06:00|   06-25 15:00:00| 06-25 17:00:00|121.40357|37.53632| 21485|       1|06-25 16:47:00|           NULL|          NULL|          NULL|           NULL|          NULL|          NULL| 625|\n",
      "|  545039|        2|Hangzhou|      9425|10-13 12:52:00|   10-13 12:52:00| 10-13 14:52:00| 120.3012|30.42453| 21755|       7|10-13 14:16:00| 10-13 14:16:00|      120.3016|      30.42488|           NULL|          NULL|          NULL|1013|\n",
      "+--------+---------+--------+----------+--------------+-----------------+---------------+---------+--------+------+--------+--------------+---------------+--------------+--------------+---------------+--------------+--------------+----+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import : from pyspark.sql.functions import rand\n",
    "df_pickup.orderBy(rand()).show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0eeb125d-3a1b-4e66-b694-9db4313cd203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records: 6136147\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of records: {df_pickup.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da25052e-86a4-4185-b57e-4960b82c3203",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Convert String Timestamps to timestamp Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64425fd3-8b8e-401f-886a-3c32f20023f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- region_id: integer (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- courier_id: integer (nullable = true)\n",
      " |-- accept_time: string (nullable = true)\n",
      " |-- time_window_start: string (nullable = true)\n",
      " |-- time_window_end: string (nullable = true)\n",
      " |-- lng: double (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- aoi_id: integer (nullable = true)\n",
      " |-- aoi_type: integer (nullable = true)\n",
      " |-- pickup_time: string (nullable = true)\n",
      " |-- pickup_gps_time: string (nullable = true)\n",
      " |-- pickup_gps_lng: double (nullable = true)\n",
      " |-- pickup_gps_lat: double (nullable = true)\n",
      " |-- accept_gps_time: string (nullable = true)\n",
      " |-- accept_gps_lng: double (nullable = true)\n",
      " |-- accept_gps_lat: double (nullable = true)\n",
      " |-- ds: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pickup.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c64df8b7-55b1-427a-972b-45ffdbbac278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current year dynamically as with adding its taking 1970 as default year as there is no year in csv file and excel is showing byfault the current year\n",
    "current_year = date_format(col(\"current_date\"), \"yyyy\")\n",
    "\n",
    "# Convert all date columns by prepending the current year\n",
    "df_pickup = df_pickup.withColumn(\"accept_time\", to_timestamp(concat(current_year, lit(\"-\"), trim(col(\"accept_time\"))), \"yyyy-MM-dd HH:mm:ss\")) \\\n",
    "       .withColumn(\"pickup_time\", to_timestamp(concat(current_year, lit(\"-\"), trim(col(\"pickup_time\"))), \"yyyy-MM-dd HH:mm:ss\")) \\\n",
    "       .withColumn(\"pickup_gps_time\", to_timestamp(concat(current_year, lit(\"-\"), trim(col(\"pickup_gps_time\"))), \"yyyy-MM-dd HH:mm:ss\")) \\\n",
    "       .withColumn(\"accept_gps_time\", to_timestamp(concat(current_year, lit(\"-\"), trim(col(\"accept_gps_time\"))), \"yyyy-MM-dd HH:mm:ss\")) \\\n",
    "       .withColumn(\"time_window_start\", to_timestamp(concat(current_year, lit(\"-\"), trim(col(\"time_window_start\"))), \"yyyy-MM-dd HH:mm:ss\")) \\\n",
    "       .withColumn(\"time_window_end\", to_timestamp(concat(current_year, lit(\"-\"), trim(col(\"time_window_end\"))), \"yyyy-MM-dd HH:mm:ss\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c18de7f1-8eaf-4814-8f84-bdf32801b28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- region_id: integer (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- courier_id: integer (nullable = true)\n",
      " |-- accept_time: timestamp (nullable = true)\n",
      " |-- time_window_start: timestamp (nullable = true)\n",
      " |-- time_window_end: timestamp (nullable = true)\n",
      " |-- lng: double (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- aoi_id: integer (nullable = true)\n",
      " |-- aoi_type: integer (nullable = true)\n",
      " |-- pickup_time: timestamp (nullable = true)\n",
      " |-- pickup_gps_time: timestamp (nullable = true)\n",
      " |-- pickup_gps_lng: double (nullable = true)\n",
      " |-- pickup_gps_lat: double (nullable = true)\n",
      " |-- accept_gps_time: timestamp (nullable = true)\n",
      " |-- accept_gps_lng: double (nullable = true)\n",
      " |-- accept_gps_lat: double (nullable = true)\n",
      " |-- ds: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pickup.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6d7746c-0110-4647-ad09-d2f52cf3b330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|        pickup_time|\n",
      "+-------------------+\n",
      "|2025-07-14 17:14:00|\n",
      "|2025-07-19 08:47:00|\n",
      "|2025-10-20 17:50:00|\n",
      "|2025-10-29 17:00:00|\n",
      "|2025-10-16 09:56:00|\n",
      "+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pickup.select(\"pickup_time\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048d31d4-94f4-44a7-ada2-eb0dbfbd4da0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Dropping Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "991d135e-2e24-431c-9f6a-16508e847109",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pickup = df_pickup.dropDuplicates([\"order_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696c8acc-5e89-4e01-b8ea-2d47f4ef343c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Handle missing values using dropna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dfa0730-1317-4d5f-b55c-f206b80658dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping order_id and courier_idif they are missing as they are important\n",
    "df_pickup = df_pickup.dropna(subset=[\"order_id\", \"courier_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c7528f5-5ac5-4aee-a9c6-b9c5f1bf84fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records: 6136147\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of records: {df_pickup.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece4e899-9a03-4538-bd0b-679dd962d611",
   "metadata": {},
   "source": [
    "### Handle Missing values using imputation strategies where necessary. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7802c425-f3cf-4097-a8d2-3e33e65f8a25",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Mean Imputation for Numeric Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f817e2c-7889-458f-b38f-7da58ae484f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [\"lng\", \"lat\", \"pickup_gps_lng\", \"pickup_gps_lat\", \"accept_gps_lng\", \"accept_gps_lat\"]\n",
    "\n",
    "# Create Imputer to fill missing numeric values with mean\n",
    "imputer = Imputer(inputCols=numeric_cols, outputCols=[c + \"_imputed\" for c in numeric_cols], strategy=\"mean\")\n",
    "\n",
    "# Apply Imputer\n",
    "df_pickup = imputer.fit(df_pickup).transform(df_pickup)\n",
    "# Round the imputed values to 5 decimal places\n",
    "for col_name in numeric_cols:\n",
    "    df_pickup = df_pickup.withColumn(col_name + \"_imputed\", round(col(col_name + \"_imputed\"), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e161dace-1dc1-49b2-9541-28ab35b31d4e",
   "metadata": {},
   "source": [
    "##### To Check the imputed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3ebb9ec-c558-43c6-a46d-a294d6f8871e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------------+--------------+--------------+--------------+-----------+-----------+----------------------+----------------------+----------------------+----------------------+\n",
      "|      lng|     lat|pickup_gps_lng|pickup_gps_lat|accept_gps_lng|accept_gps_lat|lng_imputed|lat_imputed|pickup_gps_lng_imputed|pickup_gps_lat_imputed|accept_gps_lng_imputed|accept_gps_lat_imputed|\n",
      "+---------+--------+--------------+--------------+--------------+--------------+-----------+-----------+----------------------+----------------------+----------------------+----------------------+\n",
      "|120.05093|30.37981|     120.04952|       30.3713|     120.05035|      30.36885|  120.05093|   30.37981|             120.04952|               30.3713|             120.05035|              30.36885|\n",
      "|120.05162|30.37836|      120.0515|      30.37853|     120.05515|      30.38345|  120.05162|   30.37836|              120.0515|              30.37853|             120.05515|              30.38345|\n",
      "|120.05046|30.37844|          NULL|          NULL|          NULL|          NULL|  120.05046|   30.37844|             118.38133|              32.57753|             118.54136|              32.70376|\n",
      "|120.05242|30.38059|     120.05268|      30.38056|      120.0743|      30.38605|  120.05242|   30.38059|             120.05268|              30.38056|              120.0743|              30.38605|\n",
      "|120.05038|30.37835|     120.05027|      30.37838|     120.05585|      30.37965|  120.05038|   30.37835|             120.05027|              30.37838|             120.05585|              30.37965|\n",
      "+---------+--------+--------------+--------------+--------------+--------------+-----------+-----------+----------------------+----------------------+----------------------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define numeric columns that were imputed\n",
    "numeric_cols = [\"lng\", \"lat\",\"pickup_gps_lng\", \"pickup_gps_lat\", \"accept_gps_lng\", \"accept_gps_lat\"]\n",
    "# Select original and imputed columns for comparison\n",
    "df_pickup.select([col(c) for c in numeric_cols] + [col(c + \"_imputed\") for c in numeric_cols]).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311e3c50-866a-475f-b2c0-3b0a4d94ecd4",
   "metadata": {},
   "source": [
    "##### Drop original columns and rename imputed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74ecb495-90ec-4abf-8fd1-ff4ca0985da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in numeric_cols:\n",
    "    df_pickup = df_pickup.drop(col_name).withColumnRenamed(col_name + \"_imputed\", col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fe6a1fc-a090-4eed-95f7-1141b87c7b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+---------+----------+-------------------+-------------------+-------------------+------+--------+-------------------+-------------------+-------------------+---+---------+--------+--------------+--------------+--------------+--------------+\n",
      "|order_id|region_id|     city|courier_id|        accept_time|  time_window_start|    time_window_end|aoi_id|aoi_type|        pickup_time|    pickup_gps_time|    accept_gps_time| ds|      lng|     lat|pickup_gps_lng|pickup_gps_lat|accept_gps_lng|accept_gps_lat|\n",
      "+--------+---------+---------+----------+-------------------+-------------------+-------------------+------+--------+-------------------+-------------------+-------------------+---+---------+--------+--------------+--------------+--------------+--------------+\n",
      "|      31|       43| Shanghai|      8956|2025-09-12 14:28:00|2025-09-12 15:00:00|2025-09-12 17:00:00| 14530|       1|2025-09-12 14:37:00|2025-09-12 14:37:00|2025-09-12 14:28:00|912|121.54796|31.23265|      121.5488|      31.23259|     121.54716|      31.23162|\n",
      "|      53|        6| Shanghai|      2204|2025-09-18 16:50:00|2025-09-18 16:50:00|2025-09-18 18:50:00| 13521|       1|2025-09-18 17:09:00|2025-09-18 17:09:00|2025-09-18 16:50:00|918|121.52641|31.23276|     121.52611|      31.23261|      121.5247|      31.23336|\n",
      "|      65|       92| Hangzhou|     10698|2025-08-08 09:09:00|2025-08-08 13:00:00|2025-08-08 15:00:00| 13145|       1|2025-08-08 11:42:00|2025-08-08 11:41:00|2025-08-08 09:09:00|808|120.16357|  30.385|     120.16395|      30.38743|     120.16349|      30.38351|\n",
      "|      78|       54| Shanghai|     14894|2025-09-23 08:31:00|2025-09-23 11:00:00|2025-09-23 13:00:00|  9527|       1|2025-09-23 11:27:00|               NULL|               NULL|923|121.36685|31.34691|     118.38133|      32.57753|     118.54136|      32.70376|\n",
      "|      85|       60|Chongqing|      3953|2025-07-22 15:53:00|2025-07-22 16:00:00|2025-07-22 18:00:00|  3311|       4|2025-07-22 16:54:00|2025-07-22 16:52:00|2025-07-22 15:49:00|722|108.71135|30.92845|     108.71028|      30.92823|     108.71451|      30.92935|\n",
      "+--------+---------+---------+----------+-------------------+-------------------+-------------------+------+--------+-------------------+-------------------+-------------------+---+---------+--------+--------------+--------------+--------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pickup.select(\"*\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af94007-93f1-4c1e-b442-e41b6f7397c6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Mode Imputation for Categorical Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1bcedf7-0a53-452c-ab34-003993eff88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For categorical fields (city, region_id, aoi_type), we replace missing values with the most frequent value (mode).\n",
    "categorical_cols = [\"city\", \"region_id\", \"aoi_type\"]\n",
    "\n",
    "for cat_cols in categorical_cols:\n",
    "    mode_value = df_pickup.groupBy(cat_cols).count().orderBy(col(\"count\").desc()).first()[0] # Get most frequent value\n",
    "    df_pickup.fillna({cat_cols: mode_value}) # Fill missing values with mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6957d6ff-afe3-48cf-9f8a-1b113811253b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------+\n",
      "|     city|region_id|aoi_type|\n",
      "+---------+---------+--------+\n",
      "| Shanghai|       43|       1|\n",
      "| Shanghai|        6|       1|\n",
      "| Hangzhou|       92|       1|\n",
      "| Shanghai|       54|       1|\n",
      "|Chongqing|       60|       4|\n",
      "+---------+---------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pickup.select(\"city\", \"region_id\", \"aoi_type\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daa7a39-a804-48f2-9595-e84aa8a2c6ff",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Forward Fill (Last Known Value) for Timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f6cb2c-f8aa-4492-9b19-0172315b6123",
   "metadata": {},
   "source": [
    "##### Removing unnecessary columns i.e. pickup_gps_time and accept_gps_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f1be4e2-b3f5-4d37-9c9d-b4b3fb9b8eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before filling the timestamp notice in the csv file that pickup_time and pickup_gps_time have same values same for accept_time & accept_gps_time.\n",
    "# therefore we can drop these columns pickup_gps_time and accept_gps_time.\n",
    "# Assuming you have a DataFrame named df\n",
    "df_pickup = df_pickup.drop('pickup_gps_time', 'accept_gps_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ef66c91-141c-4e8a-932e-c798ee01800b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- region_id: integer (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- courier_id: integer (nullable = true)\n",
      " |-- accept_time: timestamp (nullable = true)\n",
      " |-- time_window_start: timestamp (nullable = true)\n",
      " |-- time_window_end: timestamp (nullable = true)\n",
      " |-- aoi_id: integer (nullable = true)\n",
      " |-- aoi_type: integer (nullable = true)\n",
      " |-- pickup_time: timestamp (nullable = true)\n",
      " |-- ds: integer (nullable = true)\n",
      " |-- lng: double (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- pickup_gps_lng: double (nullable = true)\n",
      " |-- pickup_gps_lat: double (nullable = true)\n",
      " |-- accept_gps_lng: double (nullable = true)\n",
      " |-- accept_gps_lat: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pickup.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9eb631-fe74-4ef1-ab15-f9c7d1f2da18",
   "metadata": {},
   "source": [
    "##### Forward/Backward Filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6090df7a-12fd-42ac-9dfd-138ad34416f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first row in a partition (grouped by courier_id) remains NULL because there is no previous value to carry forward. \n",
    "# The forward fill approach only propagates past values forward, but it doesn't backfill the first row if it was originally NULL in the very starting rows.\n",
    "# To fix this, we need to first fill missing values with the earliest available timestamp in the partition (backfill), then apply forward filling\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Define a global forward-fill and backward-fill window\n",
    "window_forward = Window.orderBy(\"accept_time\").rowsBetween(-sys.maxsize, 0)  # Forward fill\n",
    "window_backward = Window.orderBy(F.col(\"accept_time\").desc()).rowsBetween(-sys.maxsize, 0)  # Backward fill\n",
    "\n",
    "time_cols = [\"accept_time\", \"pickup_time\", \"time_window_start\", \"time_window_end\"]\n",
    "\n",
    "for time_col in time_cols:\n",
    "    df_pickup = df_pickup.withColumn(time_col, \n",
    "        F.coalesce(\n",
    "            F.last(time_col, ignorenulls=True).over(window_forward),  # Forward fill\n",
    "            F.first(time_col, ignorenulls=True).over(window_backward)  # Backward fill\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cf03c38-1dc8-4e8b-b4dd-1495bd66b6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------------+-------------------+\n",
      "|        pickup_time|        accept_time|  time_window_start|    time_window_end|\n",
      "+-------------------+-------------------+-------------------+-------------------+\n",
      "|2025-08-20 10:09:00|2025-08-20 07:37:00|2025-08-20 09:00:00|2025-08-20 11:00:00|\n",
      "+-------------------+-------------------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pickup.filter(df_pickup.order_id == \"19\").select(\"pickup_time\", \"accept_time\", \"time_window_start\", \"time_window_end\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dfa57ee8-346d-4481-b437-1b72d8f956d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----------------+---------------+\n",
      "|accept_time|pickup_time|time_window_start|time_window_end|\n",
      "+-----------+-----------+-----------------+---------------+\n",
      "|          0|          0|                0|              0|\n",
      "+-----------+-----------+-----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pickup.select([count(when(col(c).isNull(), 1)).alias(c) for c in time_cols]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76933e5a-1822-4b77-b779-59ab383bd3a0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Convert categorical fields (e.g., aoi_type, city, region_id) to a consistent format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70982b0b-1201-42f8-9853-98e21da44f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pickup = df_pickup.withColumn(\"city\", trim(initcap(col(\"city\")))) \\\n",
    "       .withColumn(\"region_id\", col(\"region_id\").cast(\"int\")) \\\n",
    "       .withColumn(\"aoi_type\", col(\"aoi_type\").cast(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2991124-08aa-48fa-917d-9ccaab79e801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------+\n",
      "|     city|region_id|aoi_type|\n",
      "+---------+---------+--------+\n",
      "| Shanghai|       43|       1|\n",
      "| Shanghai|        6|       1|\n",
      "| Hangzhou|       92|       1|\n",
      "| Shanghai|       54|       1|\n",
      "|Chongqing|       60|       4|\n",
      "+---------+---------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pickup.select(\"city\", \"region_id\", \"aoi_type\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07061111-6702-477f-bae9-1198a40676da",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Removing or fixing inconsistent geospatial coordinates (lng/lat)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c15775d-068f-402a-b26c-c21cfdbd21a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_cols = [\"lat\", \"pickup_gps_lat\", \"accept_gps_lat\"]\n",
    "lng_cols = [\"lng\", \"pickup_gps_lng\", \"accept_gps_lng\"]\n",
    "\n",
    "# Keep only valid latitudes (-90 to 90)\n",
    "for col_name in lat_cols:\n",
    "    df_pickup = df_pickup.withColumn(col_name, when((col(col_name) >= -90) & (col(col_name) <= 90), col(col_name)).otherwise(None))\n",
    "\n",
    "# Keep only valid longitudes (-180 to 180)\n",
    "for col_name in lng_cols:\n",
    "    df_pickup = df_pickup.withColumn(col_name, when((col(col_name) >= -180) & (col(col_name) <= 180), col(col_name)).otherwise(None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6b18ba0-a72c-468f-9ebe-8bb8ebe8c8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------------+--------------+--------------+--------------+\n",
      "|      lng|     lat|pickup_gps_lng|pickup_gps_lat|accept_gps_lng|accept_gps_lat|\n",
      "+---------+--------+--------------+--------------+--------------+--------------+\n",
      "|120.05093|30.37981|     120.04952|       30.3713|     120.05035|      30.36885|\n",
      "|120.05162|30.37836|      120.0515|      30.37853|     120.05515|      30.38345|\n",
      "|120.05046|30.37844|     118.38133|      32.57753|     118.54136|      32.70376|\n",
      "|120.05242|30.38059|     120.05268|      30.38056|      120.0743|      30.38605|\n",
      "|120.05038|30.37835|     120.05027|      30.37838|     120.05585|      30.37965|\n",
      "+---------+--------+--------------+--------------+--------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pickup.select(\"lng\", \"lat\",\"pickup_gps_lng\", \"pickup_gps_lat\", \"accept_gps_lng\", \"accept_gps_lat\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a444fbc-7b57-4d0c-968a-0293f04593d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+--------------+--------------+--------------+--------------+\n",
      "|lng|lat|pickup_gps_lng|pickup_gps_lat|accept_gps_lng|accept_gps_lat|\n",
      "+---+---+--------------+--------------+--------------+--------------+\n",
      "|  0|  0|             0|             0|             0|             0|\n",
      "+---+---+--------------+--------------+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#checking any of the column is still null \n",
    "time_cols = [\"lng\", \"lat\",\"pickup_gps_lng\", \"pickup_gps_lat\", \"accept_gps_lng\", \"accept_gps_lat\"]\n",
    "df_pickup.select([count(when(col(c).isNull(), 1)).alias(c) for c in time_cols]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914a3cfb-1d19-4099-be1f-a8f2d7973f50",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Identify any anomalies in timestamps (e.g., deliveries before pickups) & Checking for incorrect or negative time differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f14a2ed-41af-4606-9ce9-875d6349a172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for \"accepts before pickups\" (accept_time > pickup_time)\n",
    "df_pickup = df_pickup.withColumn(\n",
    "    \"accept_before_pickup\",\n",
    "    when(col(\"accept_time\") > col(\"pickup_time\"), True).otherwise(False)\n",
    ")\n",
    "\n",
    "# Check for negative or incorrect time differences between accept_time and pickup_time\n",
    "df_pickup = df_pickup.withColumn(\n",
    "    \"time_difference\",\n",
    "    (unix_timestamp(\"pickup_time\") - unix_timestamp(\"accept_time\"))\n",
    ")\n",
    "\n",
    "# Flag negative time differences\n",
    "df_pickup = df_pickup.withColumn(\n",
    "    \"negative_time_difference\",\n",
    "    when(col(\"time_difference\") < 0, True).otherwise(False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba1f10a6-20ec-4e69-80bf-3e5a029847e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------------+\n",
      "|accept_before_pickup|negative_time_difference|\n",
      "+--------------------+------------------------+\n",
      "+--------------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter for anomalies\n",
    "anomalies = df_pickup.filter((col(\"accept_before_pickup\") == True) | (col(\"negative_time_difference\") == True))\n",
    "\n",
    "# Show anomalies\n",
    "anomalies.select(\"accept_before_pickup\", \"negative_time_difference\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb70488a-cc03-47ad-b25a-2fb5d9c4c20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pickup = df_pickup.drop('accept_before_pickup','time_difference', 'negative_time_difference')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae96c09e-220d-4bde-82eb-15c116330b46",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Creating derived feature: Pickup ETA = pickup_time - accept_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66a00ea0-61c9-4ba6-aebf-4b33c3775acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Calculate Pickup Delay\n",
    "df_pickup = df_pickup.withColumn(\n",
    "    \"pickup_eta_minutes\", \n",
    "    ((F.unix_timestamp(\"pickup_time\") - F.unix_timestamp(\"accept_time\"))/60).cast(\"double\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63879637-de7f-4d8b-b856-7eda07fc848a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|pickup_eta_minutes|\n",
      "+------------------+\n",
      "|              17.0|\n",
      "|              22.0|\n",
      "|              30.0|\n",
      "|              52.0|\n",
      "|              17.0|\n",
      "+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pickup.select('pickup_eta_minutes').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7764c017-3bbc-47f4-bce1-331748d09d14",
   "metadata": {},
   "source": [
    "### Saving the cleaned data in a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4f49bc3-42c8-42b1-b582-f309fcb6492a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Pickup data saved successfully\n"
     ]
    }
   ],
   "source": [
    "time_cols = [\"accept_time\", \"pickup_time\", \"time_window_start\", \"time_window_end\"]\n",
    "\n",
    "# Format the timestamp columns to match the desired format as directly saving to csv file is giving wrong format for dates columns.\n",
    "for time_col in time_cols:\n",
    "    df_pickup = df_pickup.withColumn(\n",
    "        time_col, \n",
    "        date_format(time_col, \"yyyy-MM-dd HH:mm:ss\")\n",
    "    )\n",
    "\n",
    "output_path = r'C:\\Users\\Dusty\\Downloads\\Internship\\Last-Mile-Delivery-Delays-and-Route-Optimization\\data\\cleaned_pickup_data.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df_pickup.coalesce(1).write.csv(output_path, header=True, mode=\"overwrite\")\n",
    "print(f\"Cleaned Pickup data saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ded56625-60f9-438b-9c02-2da79c26a3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the DataFrame: 6136147\n"
     ]
    }
   ],
   "source": [
    "row_count = df_pickup.count()\n",
    "print(f\"Number of rows in the DataFrame: {row_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908b73cb-3605-458f-9925-ed79fc0fa6d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
